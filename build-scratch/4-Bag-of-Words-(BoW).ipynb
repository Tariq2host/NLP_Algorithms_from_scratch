{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L'algorithme de Bag of Words (BoW)**\n",
    "\n",
    "Le **Bag of Words (BoW)** est une méthode classique utilisée en traitement du langage naturel (NLP) pour représenter du texte sous forme de vecteurs numériques. \n",
    "\n",
    "---\n",
    "\n",
    "### **Principe**\n",
    "L'idée principale est de représenter un document en fonction des mots qu'il contient, sans prendre en compte leur ordre ou leur contexte grammatical. C'est comme si on \"jetait\" tous les mots dans un sac, d'où le nom.\n",
    "\n",
    "#### Étapes de l'algorithme :\n",
    "1. **Collecte des documents** : On commence par une collection de textes (corpus).\n",
    "2. **Tokenisation** : On divise chaque document en une liste de mots ou de tokens.\n",
    "3. **Création du vocabulaire** :\n",
    "   - On crée un vocabulaire unique contenant tous les mots du corpus, souvent après une étape de nettoyage (comme la suppression des stop words, le stemming, ou la lemmatisation).\n",
    "4. **Vectorisation** :\n",
    "   - Chaque document est représenté par un vecteur où chaque dimension correspond à un mot du vocabulaire.\n",
    "   - La valeur associée à chaque dimension indique combien de fois le mot apparaît dans le document (fréquence brute).\n",
    "\n",
    "#### Exemple :\n",
    "Supposons un corpus avec ces deux phrases :\n",
    "1. \"Le chat dort.\"\n",
    "2. \"Le chien court.\"\n",
    "\n",
    "- **Vocabulaire** : \\[\"chat\", \"dort\", \"chien\", \"court\", \"le\"\\].\n",
    "- **Vecteur pour \"Le chat dort\"** : \\[1, 1, 0, 0, 1\\].\n",
    "- **Vecteur pour \"Le chien court\"** : \\[0, 0, 1, 1, 1\\].\n",
    "\n",
    "---\n",
    "\n",
    "### **Variantes**\n",
    "1. **TF (Term Frequency)** : Remplace la fréquence brute par la fréquence relative d’un mot dans un document.\n",
    "2. **TF-IDF (Term Frequency-Inverse Document Frequency)** : Pondère les mots en fonction de leur importance dans le corpus.\n",
    "\n",
    "---\n",
    "\n",
    "### **Utilité de Bag of Words**\n",
    "1. **Représentation des textes** :\n",
    "   - Simplifie le texte en un format mathématique (vecteurs) utilisable par des modèles de machine learning.\n",
    "2. **Applications courantes** :\n",
    "   - **Classification de texte** : Spam vs non-spam, analyse de sentiments.\n",
    "   - **Recherche documentaire** : Trouver des documents similaires.\n",
    "   - **Clustering de documents** : Grouper des documents en fonction de leur contenu.\n",
    "3. **Rapide et simple** :\n",
    "   - Convient pour des tâches basiques ou comme baseline.\n",
    "\n",
    "---\n",
    "\n",
    "### **Limites**\n",
    "1. **Perte de contexte** : L'ordre des mots est ignoré, ce qui peut être problématique pour des phrases comme \"Le chat chasse le chien\" vs \"Le chien chasse le chat\".\n",
    "2. **Grande dimensionnalité** : Pour un corpus large, le vocabulaire devient énorme, augmentant les besoins en mémoire.\n",
    "3. **Non interprétation du sens** : Tous les mots sont traités de manière indépendante.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Le **Bag of Words** est une méthode simple mais puissante pour les tâches NLP de base. Cependant, avec l'avènement des techniques avancées comme les word embeddings (Word2Vec, GloVe) ou les modèles transformers (BERT), il est souvent remplacé pour des applications plus complexes nécessitant une compréhension contextuelle."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
